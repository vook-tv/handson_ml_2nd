{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Chapter16_RNN과_어텐션을_사용한_자연어_처리.ipynb","provenance":[{"file_id":"1Qs_NCwCkKwMab2CKwf7poEyvbErSWk7e","timestamp":1609558348516}],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"widgets":{"application/vnd.jupyter.widget-state+json":{"045b71b091174c2e84c7e449b463e42a":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_196ed5913f7542ccb5b7f7ef2c708bd2","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_85085b4bd94249f4bf060c7f0de34430","IPY_MODEL_4ddbcae4f1d44db9a0b5f4363641daaf"]}},"196ed5913f7542ccb5b7f7ef2c708bd2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"85085b4bd94249f4bf060c7f0de34430":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_b6d1accb194846cfa905b3a7b24c3ac9","_dom_classes":[],"description":"Dl Completed...: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":1,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":1,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_dcb6d1d583fd47e595f64d6c98949435"}},"4ddbcae4f1d44db9a0b5f4363641daaf":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_88df71cba4924c8f9144d3db65dec65f","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 1/1 [00:04&lt;00:00,  4.85s/ url]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_bc3470ea91404a13be59c47d13437d52"}},"b6d1accb194846cfa905b3a7b24c3ac9":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"dcb6d1d583fd47e595f64d6c98949435":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"88df71cba4924c8f9144d3db65dec65f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"bc3470ea91404a13be59c47d13437d52":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"72d36fd800774bf081a30ee5ebd08eef":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_dc5e59e27ede4a0daea325a704fe7779","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_e76e0a1759574c0fb7748b8471267e0d","IPY_MODEL_e507edd5569b40739507798143821bc2"]}},"dc5e59e27ede4a0daea325a704fe7779":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"e76e0a1759574c0fb7748b8471267e0d":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_110f62b861764e59aa2f81f03400d498","_dom_classes":[],"description":"Dl Size...: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":1,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":1,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_1b4626a2b8c84fd78d110973803046f5"}},"e507edd5569b40739507798143821bc2":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_ab16605cf81242bdb11d0548697faa48","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 80/80 [00:04&lt;00:00, 16.59 MiB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_dab9864f22314232bcacc354d3792f44"}},"110f62b861764e59aa2f81f03400d498":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"1b4626a2b8c84fd78d110973803046f5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"ab16605cf81242bdb11d0548697faa48":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"dab9864f22314232bcacc354d3792f44":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"843208cd72e54058a40c469b26a9ca94":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_2a780cc253eb4850a3e112c29ff8545b","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_381e1fb49909442fa78c83daed0eb0ff","IPY_MODEL_0cbaff34e57d4b97991ce26875d37f06"]}},"2a780cc253eb4850a3e112c29ff8545b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"381e1fb49909442fa78c83daed0eb0ff":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_e8bcd443fc0b4ae7925b5585aba4160c","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"info","max":1,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":1,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_6abe79ebad9a41a7a2f4a18e2ee93ac4"}},"0cbaff34e57d4b97991ce26875d37f06":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_244047ab56ab4b029529d272205e0a46","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 25000/0 [00:13&lt;00:00, 3226.56 examples/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_986ed7d6cd984746a6019522216fa035"}},"e8bcd443fc0b4ae7925b5585aba4160c":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"6abe79ebad9a41a7a2f4a18e2ee93ac4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"244047ab56ab4b029529d272205e0a46":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"986ed7d6cd984746a6019522216fa035":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"eb028a19f78344afb6e1443da9780009":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_c6759e936bab47b0888e6675c1ae652b","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_5c66e8401a694cc9b5d6b85b60044b5a","IPY_MODEL_18e8280bd617406da8c053ee25c99922"]}},"c6759e936bab47b0888e6675c1ae652b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"5c66e8401a694cc9b5d6b85b60044b5a":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_05eb628dd10d4d31af1b7fd6354c7e27","_dom_classes":[],"description":" 40%","_model_name":"FloatProgressModel","bar_style":"danger","max":25000,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":10110,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_4efe3011b6064ad483ca8058a6fd299b"}},"18e8280bd617406da8c053ee25c99922":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_644d80a6840e433682b53ae88fd8bb56","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 10110/25000 [00:00&lt;00:00, 101098.17 examples/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_9f9d8d9ae2f44e2398c09949e24fd4d0"}},"05eb628dd10d4d31af1b7fd6354c7e27":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"4efe3011b6064ad483ca8058a6fd299b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"644d80a6840e433682b53ae88fd8bb56":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"9f9d8d9ae2f44e2398c09949e24fd4d0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"76a9b9fd1a0242f3ad245dff33247e00":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_ea90dc301965429b82641bf46e3729cc","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_e3fa85831d5c4f549c5f59140f36051b","IPY_MODEL_efe1d7cc348344bdb59cf585f6b32440"]}},"ea90dc301965429b82641bf46e3729cc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"e3fa85831d5c4f549c5f59140f36051b":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_5f30fbe2259e423081da45d332a5304b","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"info","max":1,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":1,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_8e75aca66c934ce89ec757f942c9c787"}},"efe1d7cc348344bdb59cf585f6b32440":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_8206615b0c6c48f9ba2f36b3bef0d1b6","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 25000/0 [00:13&lt;00:00, 3330.39 examples/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_36e2c1acafa44f81b394410da502da47"}},"5f30fbe2259e423081da45d332a5304b":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"8e75aca66c934ce89ec757f942c9c787":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"8206615b0c6c48f9ba2f36b3bef0d1b6":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"36e2c1acafa44f81b394410da502da47":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"9e55bbd8936849ac8c8a1a1c7dd34946":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_6c795bd6ae9b4b68b24b2c97fe344f84","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_658ed0535f424adbb54766ba31dcbad3","IPY_MODEL_ee6d840bf532422bb75a8d008a337d1d"]}},"6c795bd6ae9b4b68b24b2c97fe344f84":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"658ed0535f424adbb54766ba31dcbad3":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_d7dd20bdf32242bb9188b4d9bedb29b1","_dom_classes":[],"description":" 17%","_model_name":"FloatProgressModel","bar_style":"danger","max":25000,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":4362,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_de6569ceceff46b1ad9c4210203822b3"}},"ee6d840bf532422bb75a8d008a337d1d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_c0b90933ac3844bb904db05d4f00ba24","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 4362/25000 [00:00&lt;00:00, 43619.42 examples/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_e54ae505fab74f4aa96f7bff24f7439e"}},"d7dd20bdf32242bb9188b4d9bedb29b1":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"de6569ceceff46b1ad9c4210203822b3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"c0b90933ac3844bb904db05d4f00ba24":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"e54ae505fab74f4aa96f7bff24f7439e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"24a3c78258ad4336ac84667b12842340":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_3079a6e1d41e4eb2ab075435672dff15","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_2c58462eb1a4445c8a033250d64b2a9e","IPY_MODEL_57015f038e2945f8b2e8214b48b1f00e"]}},"3079a6e1d41e4eb2ab075435672dff15":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"2c58462eb1a4445c8a033250d64b2a9e":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_c8e7cd355f8b41918dcc3c9799b2c53c","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"info","max":1,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":1,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_b773cb0b9a44487680fbd87dc3b4500c"}},"57015f038e2945f8b2e8214b48b1f00e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_78e91e85cc3d40b3818946474a2ff14f","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 50000/0 [00:19&lt;00:00, 3303.25 examples/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_6b8bb7dcff5b48fdbd2d7da974c8775a"}},"c8e7cd355f8b41918dcc3c9799b2c53c":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"b773cb0b9a44487680fbd87dc3b4500c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"78e91e85cc3d40b3818946474a2ff14f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"6b8bb7dcff5b48fdbd2d7da974c8775a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"653bcaac3a22438d9a574ecfb6f6361c":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_bf8cfe92e00346f7b6d55c8b2679d2be","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_8228b2850449430487c27ef27d2fdcd0","IPY_MODEL_b282a9d5afed47cc9a547ad59e7f8524"]}},"bf8cfe92e00346f7b6d55c8b2679d2be":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"8228b2850449430487c27ef27d2fdcd0":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_f34448776e1a41e6843ae81b9925a0d7","_dom_classes":[],"description":"100%","_model_name":"FloatProgressModel","bar_style":"danger","max":50000,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":49774,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_1aedc34fdefd499da640332c323214a0"}},"b282a9d5afed47cc9a547ad59e7f8524":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_bfab6aa25c494f80a2e8df8d8b73dfeb","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 49774/50000 [00:00&lt;00:00, 30983.27 examples/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_af628adc84ff4e4f8160dfe3e3a9be7a"}},"f34448776e1a41e6843ae81b9925a0d7":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"1aedc34fdefd499da640332c323214a0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"bfab6aa25c494f80a2e8df8d8b73dfeb":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"af628adc84ff4e4f8160dfe3e3a9be7a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"markdown","metadata":{"id":"a059G_XuJyra"},"source":["# 16.1 Char-RNN을 사용해 셰익스피어 문체 생성하기"]},{"cell_type":"markdown","metadata":{"id":"raLxMTcNJ65f"},"source":["## 16.1.1 훈련 데이터셋 만들기"]},{"cell_type":"code","metadata":{"id":"zxhbwVVWJ9H4"},"source":["# 책에 없지만 정상 동작을 위해 코드 추가\n","import numpy as np\n","import tensorflow as tf\n","from tensorflow import keras\n","\n","np.random.seed(42)\n","tf.random.set_seed(42)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1hSXexmdKEfN","outputId":"a9803f12-11bb-4ce7-ea1a-2697dea4bf64"},"source":["shakespeare_url = \"https://homl.info/shakespeare\"\n","filepath = keras.utils.get_file(\"shakespeare.txt\", shakespeare_url)\n","\n","with open(filepath) as f :\n","  shakespeare_text = f.read()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Downloading data from https://homl.info/shakespeare\n","1122304/1115394 [==============================] - 0s 0us/step\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"1nT3NrbFKSDE"},"source":["tokenizer = keras.preprocessing.text.Tokenizer(char_level = True)\n","tokenizer.fit_on_texts(shakespeare_text)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IuHHr4S1KY6x","outputId":"915195b9-65c8-4fbb-e457-41902bac6d57"},"source":["tokenizer.texts_to_sequences([\"First\"])"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[[20, 6, 9, 8, 3]]"]},"metadata":{"tags":[]},"execution_count":4}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6kT0xz8xKdgd","outputId":"5a7862fc-f199-4687-8083-9e83af95a41f"},"source":["tokenizer.sequences_to_texts([[20, 6, 9, 8, 3]])"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['f i r s t']"]},"metadata":{"tags":[]},"execution_count":5}]},{"cell_type":"code","metadata":{"id":"8un9_-FoKhf5"},"source":["max_id = len(tokenizer.word_index) # 고유 글자 개수\n","dataset_size = tokenizer.document_count # 전체 글자 개수"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"PsX1g7K4Ko1W"},"source":["[encoded] = np.array(tokenizer.texts_to_sequences([shakespeare_text])) - 1"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Tjy1UyatKu90"},"source":["## 16.1.2 순차 데이터셋을 나누는 방법"]},{"cell_type":"code","metadata":{"id":"wPZE8-IEKxyR"},"source":["train_size = dataset_size * 90 // 100\n","dataset = tf.data.Dataset.from_tensor_slices(encoded[:train_size])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"B2N5-79JK5ew"},"source":["## 16.1.3 순차 데이터를 윈도 여러 개로 자르기"]},{"cell_type":"code","metadata":{"id":"vc9e0NngK83H"},"source":["n_steps = 100\n","window_length = n_steps + 1 # target = 1글자 앞의 input\n","dataset = dataset.window(window_length, shift = 1, drop_remainder = True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"0vOHbBjqLIoQ"},"source":["dataset = dataset.flat_map(lambda window: window.batch(window_length))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"YUatSS3cLNuN"},"source":["batch_size = 32\n","dataset = dataset.shuffle(10000).batch(batch_size)\n","dataset = dataset.map(lambda windows: (windows[:, :-1], windows[:, 1:]))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"nodRLa-TLZnK"},"source":["dataset = dataset.map(\n","    lambda X_batch, Y_batch: (tf.one_hot(X_batch, depth = max_id), Y_batch)\n",")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"1QT6m0FBLhUe"},"source":["dataset = dataset.prefetch(1)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"l9SjK-tJLjxW"},"source":["# 16.1.4 Char-RNN 모델 만들고 훈련하기"]},{"cell_type":"code","metadata":{"id":"nI8Cl-XALnyw"},"source":["model = keras.models.Sequential([\n","                                 keras.layers.GRU(128, return_sequences = True, input_shape = [None, max_id],\n","                                                  dropout = 0.2, recurrent_dropout = 0.2),\n","                                 keras.layers.GRU(128, return_sequences = True,\n","                                                  dropout = 0.2, recurrent_dropout = 0.2),\n","                                 keras.layers.TimeDistributed(keras.layers.Dense(max_id, activation = \"softmax\"))\n","])\n","model.compile(loss = \"sparse_categorical_crossentropy\", optimizer = \"adam\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WdPK3qNaMJaV","outputId":"1a9891eb-d317-4341-caaa-424ef197de4f"},"source":["history = model.fit(dataset, epochs = 1) # epochs = 20 -> 1 로 수정 (회차당 약 15,500초 소요)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["31368/31368 [==============================] - 14123s 450ms/step - loss: 1.4609\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"0A6m0DZrwPWU"},"source":["## 16.1.5 Char-RNN 모델 사용하기"]},{"cell_type":"code","metadata":{"id":"jd4SHJYSw1o7"},"source":["def preprocess(texts) :\n","  X = np.array(tokenizer.texts_to_sequences(texts)) - 1\n","  return tf.one_hot(X, max_id)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":109},"id":"wNpSjA1Xw8lJ","outputId":"019a53cc-e7fb-4d78-d7b9-dc1f016370a2"},"source":["X_new = preprocess([\"How are yo\"])\n","Y_pred = model.predict_classes(X_new)\n","tokenizer.sequences_to_texts(Y_pred + 1)[0][-1] # 첫번째 문장, 마지막 글자"],"execution_count":null,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From <ipython-input-17-ae29a0b5db34>:2: Sequential.predict_classes (from tensorflow.python.keras.engine.sequential) is deprecated and will be removed after 2021-01-01.\n","Instructions for updating:\n","Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n"],"name":"stdout"},{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'u'"]},"metadata":{"tags":[]},"execution_count":17}]},{"cell_type":"code","metadata":{"id":"hJuM9rv6xIzq"},"source":["def next_char(text, temperature = 1) :\n","  X_new = preprocess([text])\n","  y_proba = model.predict(X_new)[0, -1:, :]\n","\n","  rescaled_logits = tf.math.log(y_proba) / temperature\n","  char_id = tf.random.categorical(rescaled_logits, num_samples = 1) + 1\n","  return tokenizer.sequences_to_texts(char_id.numpy())[0]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"MeYGhqI-xhzO"},"source":["def complete_text(text, n_chars = 50, temperature = 1):\n","  for _ in range(n_chars) :\n","    text += next_char(text, temperature)\n","  return text"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sZSZFn-axrRs","outputId":"edeb05be-d793-4305-d228-d5b74cfa6b39"},"source":["print(complete_text(\"t\", temperature = 0.2))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["the time in the words.\n","\n","grumio:\n","what, sir, i shall \n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aVWXj_W4xv8d","outputId":"4aba228c-28a3-49f7-c521-f56a28d1d546"},"source":["print(complete_text(\"t\", temperature = 1))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["t i came by girl! why, sir; all he is the our end m\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ByHUzRvLyRAq","outputId":"f51a3310-bf98-4c35-d117-3b44e0988cb5"},"source":["print(complete_text(\"t\", temperature = 2))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["t-two, ho,? soft this vert,\n","you swentmed sbobbitati\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"Z0i68ktYyU5A"},"source":["## 16.1.7 상태가 있는 RNN"]},{"cell_type":"code","metadata":{"id":"ZhiVQnAkyZCu"},"source":["dataset = tf.data.Dataset.from_tensor_slices(encoded[:train_size])\n","dataset = dataset.window(window_length, shift = n_steps, drop_remainder = True)\n","dataset = dataset.flat_map(lambda window: window.batch(window_length))\n","dataset = dataset.batch(1)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"j6aKDgjKyofo"},"source":["# 정상동작을 위해 코드 추가\n","batch_size = 32\n","encoded_parts = np.array_split(encoded[:train_size], batch_size)\n","datasets = []\n","for encoded_part in encoded_parts :\n","  dataset = tf.data.Dataset.from_tensor_slices(encoded_part)\n","  dataset = dataset.window(window_length, shift = n_steps, drop_remainder = True)\n","  dataset = dataset.flat_map(lambda window: window.batch(window_length))\n","  datasets.append(dataset)\n","dataset = tf.data.Dataset.zip(tuple(datasets)).map(lambda *windows: tf.stack(windows))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"wjt-89dQzGis"},"source":["dataset = dataset.map(lambda windows: (windows[:, :-1], windows[:, 1:]))\n","dataset = dataset.map(lambda X_batch, Y_batch: (tf.one_hot(X_batch, depth = max_id), Y_batch))\n","dataset = dataset.prefetch(1)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"aMJry1PzzY-b"},"source":["model = keras.models.Sequential([\n","                                 keras.layers.GRU(128, return_sequences = True, stateful = True,\n","                                                  dropout = 0.2, recurrent_dropout = 0.2,\n","                                                  batch_input_shape = [batch_size, None, max_id]),\n","                                 keras.layers.GRU(128, return_sequences = True, stateful = True,\n","                                                  dropout = 0.2, recurrent_dropout = 0.2),\n","                                 keras.layers.TimeDistributed(keras.layers.Dense(max_id, activation = \"softmax\"))\n","])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"HdPRKcvc3jVI"},"source":["class ResetStatesCallback(keras.callbacks.Callback) :\n","  def on_epoch_begin(self, epoch, logs) :\n","    self.model.reset_states()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XDQ4CmmA3vRP","outputId":"25b9ee4a-93dd-42e3-d6b5-a0f70131739d"},"source":["model.compile(loss = \"sparse_categorical_crossentropy\", optimizer = \"adam\")\n","steps_per_epoch = 5 # 책에 없지만 코드 정상 동작을 위해 추가\n","model.fit(dataset, steps_per_epoch = steps_per_epoch, epochs = 10, callbacks = [ResetStatesCallback()]) # 코랩에서 코드 수행을위해 코드 수정 epochs = 50 -> 10"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Epoch 1/10\n","5/5 [==============================] - 2s 328ms/step - loss: 2.0603\n","Epoch 2/10\n","5/5 [==============================] - 2s 329ms/step - loss: 2.0778\n","Epoch 3/10\n","5/5 [==============================] - 2s 326ms/step - loss: 2.0587\n","Epoch 4/10\n","5/5 [==============================] - 2s 322ms/step - loss: 2.0516\n","Epoch 5/10\n","5/5 [==============================] - 2s 331ms/step - loss: 2.0622\n","Epoch 6/10\n","5/5 [==============================] - 2s 326ms/step - loss: 2.0477\n","Epoch 7/10\n","5/5 [==============================] - 2s 326ms/step - loss: 2.0585\n","Epoch 8/10\n","5/5 [==============================] - 2s 324ms/step - loss: 2.0463\n","Epoch 9/10\n","5/5 [==============================] - 2s 335ms/step - loss: 2.0299\n","Epoch 10/10\n","5/5 [==============================] - 2s 333ms/step - loss: 2.0493\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<tensorflow.python.keras.callbacks.History at 0x7f8891355b38>"]},"metadata":{"tags":[]},"execution_count":48}]},{"cell_type":"markdown","metadata":{"id":"In5o9l1T5qX2"},"source":["# 16.2 감성 분석"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7Z21HH-iWc58","outputId":"427912ff-a635-4886-c5a4-e68a76b64dbc"},"source":["(X_train, y_test), (X_valid, y_test) = keras.datasets.imdb.load_data()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n","17465344/17464789 [==============================] - 0s 0us/step\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"a5SWlrutWhCR","outputId":"d45047b2-50f5-44eb-8f12-fd20a33624f9"},"source":["X_train[0][:10]"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[1, 14, 22, 16, 43, 530, 973, 1622, 1385, 65]"]},"metadata":{"tags":[]},"execution_count":3}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"rGMRyiODWkMr","outputId":"05733b8f-5141-4324-8810-1e7d8c7665a6"},"source":["word_index = keras.datasets.imdb.get_word_index()\n","id_to_word = {id_ + 3: word for word, id_ in word_index.items()}\n","\n","for id_, token in enumerate((\"<pad>\", \"<sos>\", \"<unk>\")) :\n","  id_to_word[id_] = token\n","\n","\" \".join([id_to_word[id_] for id_ in X_train[0][:10]])"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'<sos> this film was just brilliant casting location scenery story'"]},"metadata":{"tags":[]},"execution_count":5}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":357,"referenced_widgets":["045b71b091174c2e84c7e449b463e42a","196ed5913f7542ccb5b7f7ef2c708bd2","85085b4bd94249f4bf060c7f0de34430","4ddbcae4f1d44db9a0b5f4363641daaf","b6d1accb194846cfa905b3a7b24c3ac9","dcb6d1d583fd47e595f64d6c98949435","88df71cba4924c8f9144d3db65dec65f","bc3470ea91404a13be59c47d13437d52","72d36fd800774bf081a30ee5ebd08eef","dc5e59e27ede4a0daea325a704fe7779","e76e0a1759574c0fb7748b8471267e0d","e507edd5569b40739507798143821bc2","110f62b861764e59aa2f81f03400d498","1b4626a2b8c84fd78d110973803046f5","ab16605cf81242bdb11d0548697faa48","dab9864f22314232bcacc354d3792f44","843208cd72e54058a40c469b26a9ca94","2a780cc253eb4850a3e112c29ff8545b","381e1fb49909442fa78c83daed0eb0ff","0cbaff34e57d4b97991ce26875d37f06","e8bcd443fc0b4ae7925b5585aba4160c","6abe79ebad9a41a7a2f4a18e2ee93ac4","244047ab56ab4b029529d272205e0a46","986ed7d6cd984746a6019522216fa035","eb028a19f78344afb6e1443da9780009","c6759e936bab47b0888e6675c1ae652b","5c66e8401a694cc9b5d6b85b60044b5a","18e8280bd617406da8c053ee25c99922","05eb628dd10d4d31af1b7fd6354c7e27","4efe3011b6064ad483ca8058a6fd299b","644d80a6840e433682b53ae88fd8bb56","9f9d8d9ae2f44e2398c09949e24fd4d0","76a9b9fd1a0242f3ad245dff33247e00","ea90dc301965429b82641bf46e3729cc","e3fa85831d5c4f549c5f59140f36051b","efe1d7cc348344bdb59cf585f6b32440","5f30fbe2259e423081da45d332a5304b","8e75aca66c934ce89ec757f942c9c787","8206615b0c6c48f9ba2f36b3bef0d1b6","36e2c1acafa44f81b394410da502da47","9e55bbd8936849ac8c8a1a1c7dd34946","6c795bd6ae9b4b68b24b2c97fe344f84","658ed0535f424adbb54766ba31dcbad3","ee6d840bf532422bb75a8d008a337d1d","d7dd20bdf32242bb9188b4d9bedb29b1","de6569ceceff46b1ad9c4210203822b3","c0b90933ac3844bb904db05d4f00ba24","e54ae505fab74f4aa96f7bff24f7439e","24a3c78258ad4336ac84667b12842340","3079a6e1d41e4eb2ab075435672dff15","2c58462eb1a4445c8a033250d64b2a9e","57015f038e2945f8b2e8214b48b1f00e","c8e7cd355f8b41918dcc3c9799b2c53c","b773cb0b9a44487680fbd87dc3b4500c","78e91e85cc3d40b3818946474a2ff14f","6b8bb7dcff5b48fdbd2d7da974c8775a","653bcaac3a22438d9a574ecfb6f6361c","bf8cfe92e00346f7b6d55c8b2679d2be","8228b2850449430487c27ef27d2fdcd0","b282a9d5afed47cc9a547ad59e7f8524","f34448776e1a41e6843ae81b9925a0d7","1aedc34fdefd499da640332c323214a0","bfab6aa25c494f80a2e8df8d8b73dfeb","af628adc84ff4e4f8160dfe3e3a9be7a"]},"id":"Vcy10TOdXE-9","outputId":"6b79f11c-7568-4e9b-c914-64cf33692e6c"},"source":["import tensorflow_datasets as tfds\n","\n","datasets, info = tfds.load(\"imdb_reviews\", as_supervised = True, with_info = True)\n","train_size = info.splits[\"train\"].num_examples"],"execution_count":null,"outputs":[{"output_type":"stream","text":["\u001b[1mDownloading and preparing dataset imdb_reviews/plain_text/1.0.0 (download: 80.23 MiB, generated: Unknown size, total: 80.23 MiB) to /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0...\u001b[0m\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"045b71b091174c2e84c7e449b463e42a","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Dl Completed...', max=1.0, style=Progre…"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"72d36fd800774bf081a30ee5ebd08eef","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Dl Size...', max=1.0, style=ProgressSty…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n","\n","\n","\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"843208cd72e54058a40c469b26a9ca94","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\rShuffling and writing examples to /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0.incompleteKYXL7S/imdb_reviews-train.tfrecord\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"eb028a19f78344afb6e1443da9780009","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, max=25000.0), HTML(value='')))"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\r"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"76a9b9fd1a0242f3ad245dff33247e00","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\rShuffling and writing examples to /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0.incompleteKYXL7S/imdb_reviews-test.tfrecord\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"9e55bbd8936849ac8c8a1a1c7dd34946","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, max=25000.0), HTML(value='')))"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\r"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"24a3c78258ad4336ac84667b12842340","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\rShuffling and writing examples to /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0.incompleteKYXL7S/imdb_reviews-unsupervised.tfrecord\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"653bcaac3a22438d9a574ecfb6f6361c","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, max=50000.0), HTML(value='')))"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["WARNING:absl:Dataset is using deprecated text encoder API which will be removed soon. Please use the plain_text version of the dataset and migrate to `tensorflow_text`.\n"],"name":"stderr"},{"output_type":"stream","text":["\u001b[1mDataset imdb_reviews downloaded and prepared to /root/tensorflow_datasets/imdb_reviews/plain_text/1.0.0. Subsequent calls will reuse this data.\u001b[0m\n","\r"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"NxcCpRW3XcuC"},"source":["def preprocess(X_batch, y_batch) :\n","  X_batch = tf.strings.substr(X_batch, 0, 300)\n","  X_batch = tf.strings.regex_replace(X_batch, b\"<br\\\\s*/?>\", b\" \")\n","  X_batch = tf.strings.regex_replace(X_batch, b\"[^a-zA-Z']\", b\" \")\n","  X_batch = tf.strings.split(X_batch)\n","  return X_batch.to_tensor(default_value = b\"<pad>\"), y_batch"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"0xMkMjrPX-TH"},"source":["from collections import Counter\n","\n","vocabulary = Counter()\n","for X_batch, y_batch in datasets[\"train\"].batch(32).map(preprocess) :\n","  for review in X_batch :\n","    vocabulary.update(list(review.numpy()))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EbJrOCjSYMly","outputId":"a4c074bd-2049-4158-9cda-7ecc2350a417"},"source":["vocabulary.most_common()[:3]"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[(b'<pad>', 214309), (b'the', 61137), (b'a', 38564)]"]},"metadata":{"tags":[]},"execution_count":9}]},{"cell_type":"code","metadata":{"id":"XlBxTEE8YRLb"},"source":["vocab_size = 10000\n","truncated_vocabulary = [\n","                        word for word, count in vocabulary.most_common()[:vocab_size]\n","]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Bi-oaZxWYW7t"},"source":["words = tf.constant(truncated_vocabulary)\n","word_ids = tf.range(len(truncated_vocabulary), dtype = tf.int64)\n","vocab_init = tf.lookup.KeyValueTensorInitializer(words, word_ids)\n","\n","num_oov_buckets = 1000\n","table = tf.lookup.StaticVocabularyTable(vocab_init, num_oov_buckets)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3n-Xyz-XYuCh","outputId":"74fb1a36-5028-48e0-b0bc-3437f10b4c58"},"source":["table.lookup(tf.constant([b\"This movie was faaaaaantastic\".split()]))"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<tf.Tensor: shape=(1, 4), dtype=int64, numpy=array([[   22,    12,    11, 10053]])>"]},"metadata":{"tags":[]},"execution_count":13}]},{"cell_type":"code","metadata":{"id":"MRTb4j6AZC8r"},"source":["def encode_words(X_batch, y_batch) :\n","  return table.lookup(X_batch), y_batch\n","\n","train_set = datasets[\"train\"].batch(32).map(preprocess)\n","train_set = train_set.map(encode_words).prefetch(1)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1dNUdtItZVIy","outputId":"3420d629-ab26-4703-d436-da776a567b9d"},"source":["embed_size = 128\n","model = keras.models.Sequential([\n","                                 keras.layers.Embedding(vocab_size + num_oov_buckets, embed_size,\n","                                                        input_shape = [None]),\n","                                 keras.layers.GRU(128, return_sequences = True),\n","                                 keras.layers.GRU(128),\n","                                 keras.layers.Dense(1, activation = \"sigmoid\")\n","])\n","\n","model.compile(loss = \"binary_crossentropy\", optimizer = \"adam\", metrics = [\"accuracy\"])\n","history = model.fit(train_set, epochs = 5) # 건당 약 130초 소요"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Epoch 1/5\n","782/782 [==============================] - 110s 140ms/step - loss: 0.6502 - accuracy: 0.5830\n","Epoch 2/5\n","782/782 [==============================] - 107s 137ms/step - loss: 0.4329 - accuracy: 0.8037\n","Epoch 3/5\n","782/782 [==============================] - 107s 137ms/step - loss: 0.2785 - accuracy: 0.8915\n","Epoch 4/5\n","782/782 [==============================] - 106s 136ms/step - loss: 0.1562 - accuracy: 0.9469\n","Epoch 5/5\n","782/782 [==============================] - 107s 136ms/step - loss: 0.1225 - accuracy: 0.9585\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"CfmWX0syZr5r"},"source":["## 16.2.1 마스킹 "]},{"cell_type":"code","metadata":{"id":"RV93OxImb9RB"},"source":["K = keras.backend\n","inputs = keras.layers.Input(shape = [None])\n","mask = keras.layers.Lambda(lambda inputs: K.not_equal(inputs, 0))(inputs)\n","\n","z = keras.layers.Embedding(vocab_size + num_oov_buckets, embed_size)(inputs)\n","z = keras.layers.GRU(128, return_sequences = True)(z, mask = mask)\n","z = keras.layers.GRU(128)(z, mask = mask)\n","\n","outputs = keras.layers.Dense(1, activation = \"sigmoid\")(z)\n","model = keras.models.Model(inputs = [inputs], outputs = [outputs])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"fy8ZGoY4capR"},"source":["## 16.2.2 사전 훈련된 임베딩 재사용하기"]},{"cell_type":"code","metadata":{"id":"HcOzFoBdced8"},"source":["import tensorflow_hub as hub\n","\n","model = keras.Sequential([\n","                          hub.KerasLayer(\"https://tfhub.dev/google/tf2-preview/nnlm-en-dim50/1\",\n","                                         dtype = tf.string, input_shape = [], output_shape = [50]),\n","                          keras.layers.Dense(128, activation = \"relu\"),\n","                          keras.layers.Dense(1,   activation = \"sigmoid\")\n","])\n","\n","model.compile(loss = \"binary_crossentropy\", optimizer = \"adam\", metrics = [\"accuracy\"])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_exnwaqac9Tz","outputId":"fe456f30-a92f-4084-fa3c-30571dbec3b7"},"source":["datasets, info = tfds.load(\"imdb_reviews\", as_supervised = True, with_info = True)\n","train_size = info.splits[\"train\"].num_examples\n","batch_size = 32\n","train_set = datasets[\"train\"].batch(batch_size).prefetch(1)\n","history = model.fit(train_set, epochs = 5) # 건당 약 60초 소요"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Epoch 1/5\n","782/782 [==============================] - 56s 72ms/step - loss: 0.5451 - accuracy: 0.7297\n","Epoch 2/5\n","782/782 [==============================] - 56s 72ms/step - loss: 0.5132 - accuracy: 0.7490\n","Epoch 3/5\n","782/782 [==============================] - 56s 72ms/step - loss: 0.5081 - accuracy: 0.7526\n","Epoch 4/5\n","782/782 [==============================] - 56s 72ms/step - loss: 0.5043 - accuracy: 0.7553\n","Epoch 5/5\n","782/782 [==============================] - 57s 72ms/step - loss: 0.5014 - accuracy: 0.7576\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"YDPMC52hdPdR"},"source":["# 16.3 신경망 기계 번역을 위한 인코더-디코더 네트워크"]},{"cell_type":"code","metadata":{"id":"m3S8FCLke5yh"},"source":["# 책에 없지만 코드 정상 동작을 위해 코드 추가\n","vocab_size = 100\n","embed_size = 10"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"gtrxKPk7e4lF"},"source":["import tensorflow_addons as tfa\n","\n","encoder_inputs   = keras.layers.Input(shape = [None], dtype = np.int32)\n","decoder_inputs   = keras.layers.Input(shape = [None], dtype = np.int32)\n","sequence_lengths = keras.layers.Input(shape = [],     dtype = np.int32)\n","\n","embeddings = keras.layers.Embedding(vocab_size, embed_size)\n","encoder_embeddings = embeddings(encoder_inputs)\n","decoder_embeddings = embeddings(decoder_inputs)\n","\n","encoder = keras.layers.LSTM(32, return_state = True)\n","encoder_outputs, state_h, state_c = encoder(encoder_embeddings)\n","encoder_state = [state_h, state_c]\n","\n","sampler = tfa.seq2seq.sampler.TrainingSampler()\n","\n","decoder_cell = keras.layers.LSTMCell(32)\n","output_layer = keras.layers.Dense(vocab_size)\n","decoder = tfa.seq2seq.basic_decoder.BasicDecoder(decoder_cell, sampler, output_layer = output_layer)\n","\n","final_outputs, final_state, final_sequence_lengths = decoder(\n","    decoder_embeddings, initial_state = encoder_state,\n","    sequence_length = sequence_lengths\n",")\n","\n","Y_proba = tf.nn.softmax(final_outputs.rnn_output)\n","\n","model = keras.models.Model(\n","    inputs = [encoder_inputs, decoder_inputs, sequence_lengths],\n","    outputs = [Y_proba]\n",")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"FdQaexaBgEsT"},"source":["## 16.3.1 양방향 RNN"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IqXxTw4fgTiY","outputId":"2e2147e5-4b3a-49d4-d775-0454ebc249e1"},"source":["keras.layers.Bidirectional(keras.layers.GRU(10, return_sequences = True))"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<tensorflow.python.keras.layers.wrappers.Bidirectional at 0x7f35f2484cf8>"]},"metadata":{"tags":[]},"execution_count":22}]},{"cell_type":"markdown","metadata":{"id":"q3FeMiXZgbVF"},"source":["## 16.3.2 빔 검색"]},{"cell_type":"code","metadata":{"id":"NKR7ugu-gb2p"},"source":["beam_width = 10\n","decoder = tfa.seq2seq.beam_search_decoder.BeamSearchDecoder(\n","    cell = decoder_cell, beam_width = beam_width, output_layer = output_layer)\n","\n","decoder_initial_state = tfa.seq2seq.beam_search_decoder.tile_batch(\n","    encoder_state, multiplier = beam_width\n",")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":970},"id":"aEhA5Ie7gokj","outputId":"9f974491-779d-48ee-cd48-dfa87b55e7b5"},"source":["outputs, _, _ = decoder(\n","    decoder_embeddings, start_tokens = [0], end_token = 0, # 코드 수행을 위해 embeddings_decoder -> decoder_embeddings 으로 변경\n","    initial_state = decoder_initial_state\n",")"],"execution_count":null,"outputs":[{"output_type":"error","ename":"ValueError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-34-b14bb468e846>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m outputs, _, _ = decoder(\n\u001b[1;32m      2\u001b[0m     \u001b[0mdecoder_embeddings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_tokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend_token\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;31m# 코드 수행을 위해 embeddings_decoder -> decoder_embeddings 으로 변경\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0minitial_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecoder_initial_state\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m )\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    924\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_in_functional_construction_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    925\u001b[0m       return self._functional_construction_call(inputs, args, kwargs,\n\u001b[0;32m--> 926\u001b[0;31m                                                 input_list)\n\u001b[0m\u001b[1;32m    927\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m     \u001b[0;31m# Maintains info about the `Layer.call` stack.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_functional_construction_call\u001b[0;34m(self, inputs, args, kwargs, input_list)\u001b[0m\n\u001b[1;32m   1115\u001b[0m           \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1116\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menable_auto_cast_variables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compute_dtype_object\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1117\u001b[0;31m               \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcast_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1118\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1119\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOperatorNotAllowedInGraphError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    256\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ag_error_metadata'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 258\u001b[0;31m           \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    259\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    260\u001b[0m           \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: in user code:\n\n    /usr/local/lib/python3.6/dist-packages/tensorflow_addons/seq2seq/beam_search_decoder.py:808 call  *\n        self,\n    /usr/local/lib/python3.6/dist-packages/tensorflow_addons/seq2seq/decoder.py:405 body  *\n        (next_outputs, decoder_state, next_inputs, decoder_finished) = decoder.step(\n    /usr/local/lib/python3.6/dist-packages/tensorflow_addons/seq2seq/beam_search_decoder.py:577 step  *\n        cell_outputs, next_cell_state = self._cell(\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer.py:926 __call__  **\n        input_list)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer.py:1117 _functional_construction_call\n        outputs = call_fn(cast_inputs, *args, **kwargs)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/layers/recurrent.py:2475 call\n        z = array_ops.split(z, num_or_size_splits=4, axis=1)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/util/dispatch.py:201 wrapper\n        return target(*args, **kwargs)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/array_ops.py:2011 split\n        axis=axis, num_split=num_or_size_splits, value=value, name=name)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gen_array_ops.py:9891 split\n        \"Split\", split_dim=axis, value=value, num_split=num_split, name=name)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:744 _apply_op_helper\n        attrs=attr_protos, op_def=op_def)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/func_graph.py:593 _create_op_internal\n        compute_device)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py:3485 _create_op_internal\n        op_def=op_def)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py:1975 __init__\n        control_input_ops, op_def)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py:1815 _create_c_op\n        raise ValueError(str(e))\n\n    ValueError: Dimension size must be evenly divisible by 4 but is 10\n    \tNumber of ways to split should evenly divide the split dimension for '{{node beam_search_decoder_2/decoder/while/BeamSearchDecoderStep/lstm_cell_2/split}} = Split[T=DT_FLOAT, num_split=4](beam_search_decoder_2/decoder/while/BeamSearchDecoderStep/lstm_cell_2/split/split_dim, beam_search_decoder_2/decoder/while/BeamSearchDecoderStep/lstm_cell_2/BiasAdd)' with input shapes: [], [10,10,128] and with computed input tensors: input[0] = <1>.\n"]}]},{"cell_type":"markdown","metadata":{"id":"-_WGPtyAg30h"},"source":["# 16.4 어텐션 메커니즘"]},{"cell_type":"code","metadata":{"id":"qpj-cqYxicZi"},"source":["# 책에 없지만 정상 동작을 위해 코드 추가\n","units = 128\n","encoder_state = None\n","encoder_sequence_length = None\n","\n","decoder_cell = keras.layers.LSTMCell(units)\n","attention_mechanism = 32\n","n_units = None"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"NpPTqKzGiuEv"},"source":["attention_mechanism = tfa.seq2seq.attention_wrapper.LuongAttention(\n","    units, encoder_state, memory_sequence_length = encoder_sequence_length\n",")\n","\n","attention_decoder_cell = tfa.seq2seq.attention_wrapper.AttentionWrapper(\n","    decoder_cell, attention_mechanism, attention_layer_size = n_units\n",")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"7NHy752jjBfC"},"source":["## 16.4.2 트랜스포머 구조: 어텐션이 필요한 전부다"]},{"cell_type":"markdown","metadata":{"id":"3izV10v7jGFU"},"source":["### 위치 인코딩"]},{"cell_type":"code","metadata":{"id":"siyctMLTjHKE"},"source":["class PositionalEncoding(keras.layers.Layer) :\n","  def __init__(self, max_steps, max_dims, dtype = tf.float32, **kwargs) :\n","    super().__init__(dtype = dtype, **kwargs)\n","\n","    if max_dims % 2 == 1: max_dims += 1 # max_dims는 짝수여야 합니다.\n","    p, i = np.meshgrid(np.arange(max_steps), np.arange(max_dims // 2))\n","\n","    pos_emb = np.empty((1, max_stpes, max_dims))\n","    pos_emb[0, :, ::2]  = np.sin(p / 10000 ** (2 * i / max_dims)).T\n","    pos_emb[0, :, 1::2] = np.cos(p / 10000 ** (2 * i / max_dims)).T\n","    self.positional_embedding = tf.constant(pos_emb.astype(self.dtype))\n","\n","  def call(self, inputs) :\n","    shape = tf.shape(inputs)\n","    return inputs + self.positional_embedding[:, :shape[-2], :shape[-1]]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"0Jc7eIU6j1mK"},"source":["embed_size = 512; max_steps = 500; vocab_size = 10000\n","encoder_inputs = keras.layers.Input(shape = [None], dtype = np.int32)\n","decoder_inputs = keras.layers.Input(shape = [None], dtype = np.int32)\n","\n","embeddings = keras.layers.Embedding(vocab_size, embed_size)\n","encoder_embeddings = embeddings(encoder_inputs)\n","decoder_embeddings = embeddings(decoder_inputs)\n","\n","positional_encoding = PositionalEncoding(max_steps, max_dims = embed_size)\n","encoder_in = positional_encoding(encoder_embeddings)\n","decoder_in = positional_encoding(decoder_embeddings)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"pgW4CEtnkqOy"},"source":["### 멀티-헤드 어텐션"]},{"cell_type":"code","metadata":{"id":"KFNWvC8ykyfu"},"source":["Z = encoder_in\n","\n","for N in range(6) :\n","  Z = keras.layers.Attention(use_scale = True)([Z, Z])\n","\n","encoder_outputs = Z\n","Z = decoder_in\n","for N in range(6) :\n","  Z = keras.layers.Attention(use_scale = True, causal = True)([Z, Z])\n","  Z = keras.layers.Attention(use_scale = True)([Z, encoder_outputs])\n","\n","outputs = keras.layers.TimeDistributed(\n","  keras.layers.Dense(vocab_size, activation = \"softmax\"))(Z)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZHScaN0blFQ8"},"source":[""],"execution_count":null,"outputs":[]}]}